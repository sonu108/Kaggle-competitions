{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2252270d7f435df3804fddd8d467a873e434a1d5"
   },
   "source": [
    "![](https://storage.googleapis.com/kaggle-organizations/141/thumbnail.jpg?r=890)\n",
    "# Santander Customer Transaction Prediction\n",
    "Can you identify who will make a transaction?\n",
    "\n",
    "Version6\n",
    "- Ensemble : LB 0.899\n",
    "- LightGBM : LB 0.898\n",
    "- Catboost : LB 0.898 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "7cdca812b176d9cc19bec30b12c700178571341d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 패키지 설치 \n",
    "import pandas as pd #Analysis \n",
    "import matplotlib.pyplot as plt #Visulization\n",
    "import seaborn as sns #Visulization\n",
    "import numpy as np #Analysis \n",
    "from scipy.stats import norm #Analysis \n",
    "from sklearn.preprocessing import StandardScaler #Analysis \n",
    "from scipy import stats #Analysis \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import string\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7a2000100605301248b40c0e875048a34d79c32",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking a look at how many rows and columns the train dataset contains\n",
    "rows1 = train_df.shape[0]; rows2 = test_df.shape[0]; \n",
    "columns1 = train_df.shape[1]; columns2 = test_df.shape[1]\n",
    "print(\"The train dataset contains {0} rows and {1} columns\".format(rows1, columns1))\n",
    "print(\"The test dataset contains {0} rows and {1} columns\".format(rows2, columns2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dac02272370589dee903587ee04d5d4ee45dffbf"
   },
   "source": [
    "There are some check point. \n",
    "- 1. The train and test row are similar.  \n",
    "- 2. The column size so many.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aac1a10d58f9e4063d40a62098e0f058f8ae250c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d8f7f0446ff253e5e30a94c841c8a07a4a95c80"
   },
   "source": [
    "Wow. All variable name is var_. it means that the variable is identifier !!!. https://www.kaggle.com/c/porto-seguro-safe-driver-prediction porto competition also has identifier variable. This link will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed0c0153ea8907385b705d9a549fd628d25e487f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [go.Bar(\n",
    "            x = train_df[\"target\"].value_counts().index.values,\n",
    "            y = train_df[\"target\"].value_counts().values,\n",
    "            text='Distribution of target variable'\n",
    "    )]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Target variable distribution'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8558b2bcaad208aed499860883a68d1544a8abe7"
   },
   "source": [
    "Target is unbalanced. i'll try upsampling...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c8cfb9140c90478679ca84396afb8fb0d2ac14e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-nn-approach\n",
    "def mis_value_graph(data):  \n",
    "    data = [\n",
    "    go.Bar(\n",
    "        x = data.columns,\n",
    "        y = data.isnull().sum(),\n",
    "        name = 'Counts of Missing value',\n",
    "        textfont=dict(size=20),\n",
    "        marker=dict(\n",
    "        line=dict(\n",
    "            color= generate_color(),\n",
    "            #width= 2,\n",
    "        ), opacity = 0.45\n",
    "    )\n",
    "    ),\n",
    "    ]\n",
    "    layout= go.Layout(\n",
    "        title= '\"Total Missing Value By Column\"',\n",
    "        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n",
    "        yaxis= dict(title='Value Count', ticklen=5, gridwidth=2),\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='skin')\n",
    "    \n",
    "def generate_color():\n",
    "    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: random.randint(0, 255), range(3)))\n",
    "    return color\n",
    "\n",
    "mis_value_graph(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "59dbde482ec71ee6baf4c06ea7ecfbea41f55d05",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-nn-approach\n",
    "def mis_value_graph(data):  \n",
    "    data = [\n",
    "    go.Bar(\n",
    "        x = data.columns,\n",
    "        y = data.isnull().sum(),\n",
    "        name = 'Counts of Missing value',\n",
    "        textfont=dict(size=20),\n",
    "        marker=dict(\n",
    "        line=dict(\n",
    "            color= generate_color(),\n",
    "            #width= 2,\n",
    "        ), opacity = 0.45\n",
    "    )\n",
    "    ),\n",
    "    ]\n",
    "    layout= go.Layout(\n",
    "        title= '\"Total Missing Value By Column\"',\n",
    "        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n",
    "        yaxis= dict(title='Value Count', ticklen=5, gridwidth=2),\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='skin')\n",
    "    \n",
    "def generate_color():\n",
    "    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: random.randint(0, 255), range(3)))\n",
    "    return color\n",
    "\n",
    "mis_value_graph(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4078fa3c26fa649dd203e32bc1981b59d9501d2"
   },
   "source": [
    "Train and Test has no missing value. Very Nice !!!. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "096aed71c764065e41e0aa2e4c7170f44837af50",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_int = train_df.copy()\n",
    "del train_int['ID_code']\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= train_int.corr().values,\n",
    "        x= train_int.columns.values,\n",
    "        y= train_int.columns.values,\n",
    "        colorscale='Viridis',\n",
    "        reversescale = False,\n",
    "        #text = True ,\n",
    "        opacity = 1.0 )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Pearson Correlation of Integer-type features',\n",
    "    xaxis = dict(ticks='', nticks=36),\n",
    "    yaxis = dict(ticks='' ),\n",
    "    width = 900, height = 700)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff0b13df257ae9ee849d47f7cab29e299ea4c75b"
   },
   "source": [
    "## LightGBM BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6d620e0dd22e27e639fee2bf056c0fe6528e237b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/fayzur/customer-transaction-prediction-strong-baseline\n",
    "# Thanks fayzur. Nice Parameter \n",
    "param = {\n",
    "        'num_leaves': 10,\n",
    "        'max_bin': 119,\n",
    "        'min_data_in_leaf': 11,\n",
    "        'learning_rate': 0.02,\n",
    "        'min_sum_hessian_in_leaf': 0.00245,\n",
    "        'bagging_fraction': 1.0, \n",
    "        'bagging_freq': 5, \n",
    "        'feature_fraction': 0.05,\n",
    "        'lambda_l1': 4.972,\n",
    "        'lambda_l2': 2.276,\n",
    "        'min_gain_to_split': 0.65,\n",
    "        'max_depth': 14,\n",
    "        'save_binary': True,\n",
    "        'seed': 1337,\n",
    "        'feature_fraction_seed': 1337,\n",
    "        'bagging_seed': 1337,\n",
    "        'drop_seed': 1337,\n",
    "        'data_random_seed': 1337,\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': 1,\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': True,\n",
    "        'boost_from_average': False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0775a59bf014dbbb7a8e879dd9cd3c008b56ee6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7c1952aecdc81cf4afdda7f9fdc9342e0484442",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 100)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / 5\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10ffee346217f2ff29f8aafaa99ed31490e1e9a2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,26))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('LightGBM Features (averaged over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d53f531c423fc9b9695555f1eef12771b6d88e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##submission\n",
    "sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"lgb_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6fc313aeff29c13b83db3abfcbe51ed08f7e9b1b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Catboost : https://www.kaggle.com/wakamezake/starter-code-catboost-baseline\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "model = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"AUC\")\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "y_valid_pred = 0 * target\n",
    "y_test_pred = 0\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(train_df)):\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "    X_train, X_valid = train_df[features].iloc[train_index,:], train_df[features].iloc[valid_index,:]\n",
    "    _train = Pool(X_train, label=y_train)\n",
    "    _valid = Pool(X_valid, label=y_valid)\n",
    "    print( \"\\nFold \", idx)\n",
    "    fit_model = model.fit(_train,\n",
    "                          eval_set=_valid,\n",
    "                          use_best_model=True,\n",
    "                          verbose=200\n",
    "                         )\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n",
    "    y_valid_pred.iloc[valid_index] = pred\n",
    "    y_test_pred += fit_model.predict_proba(test_df[features])[:,1]\n",
    "y_test_pred /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da02204a130a43e5efb0967350ec84fbb0d38156",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##submission\n",
    "sub_df1 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df1[\"target\"] = y_test_pred\n",
    "sub_df1.to_csv(\"cat_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b37bf176b65d0fab959625832c05bd22e1b0501f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_df = pd.merge(sub_df,sub_df1,how='left',on='ID_code')\n",
    "corr_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06da1c6f92bb4f6ad9c725569c511b084d18d1e6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##submission\n",
    "sub_df2 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df2[\"target\"] = 0.5*sub_df[\"target\"] + 0.5*sub_df1[\"target\"]\n",
    "sub_df2.to_csv(\"lgb_cat_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
